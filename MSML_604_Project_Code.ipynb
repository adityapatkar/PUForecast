{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook contains the code towards MSML604 Project for **Group 10**\n",
        "\n",
        "Members:\n",
        "- Aditya Patkar\n",
        "- Suraj T.C.\n",
        "- Carl Ostrenga\n",
        "- Nantanit Somboon\n",
        "\n",
        "Note:\n",
        "- Please upload **weight_diff.txt** into the environment or change the path below\n",
        "- One of the approach is done in MATLAB. Please check the attached MATLAB file."
      ],
      "metadata": {
        "id": "qiVvrdKu0wbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#necessary imports\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "import xgboost as xg\n",
        "\n",
        "#configuration\n",
        "filename= 'weight_diff.txt'"
      ],
      "metadata": {
        "id": "r9KC_VRi1Zyz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission 1: Logistic Regression with Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "JPSkBjEY1KZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auyvzxhz0rQ7",
        "outputId": "71d18ac5-bbb6-4d2d-e6cc-ba62f551ee9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training set...\n",
            "Training set generated\n",
            "Training time: 2.50936793\n",
            "Training size: 8350\n",
            "Success rate: [0.9701]\n",
            "Effective training time: [201.50936793]\n"
          ]
        }
      ],
      "source": [
        "def puf_query(c, w):\n",
        "    n = c.shape[1]\n",
        "    phi = np.ones(n+1)\n",
        "    phi[n] = 1\n",
        "    for i in range(n-1, -1, -1):\n",
        "        phi[i] = (2*c[0,i]-1)*phi[i+1]\n",
        "    r = (np.dot(phi, w) > 0)\n",
        "    return r\n",
        "\n",
        "# Problem Setup\n",
        "target = 0.99  # The desired prediction rate\n",
        "n = 64  # number of stages in the PUF\n",
        "\n",
        "# Initialize the PUF\n",
        "np.random.seed(int(time.time()))\n",
        "data = np.loadtxt(filename)\n",
        "w = np.zeros((n+1, 1))\n",
        "for i in range(1, n+2):\n",
        "    randi_offset = np.random.randint(1, 45481)\n",
        "    w[i-1] = data[randi_offset-1]\n",
        "\n",
        "# You can use the puf_query function to generate your training dataset\n",
        "# ADD YOUR DATASET GENERATION CODE HERE\n",
        "np.random.seed(10)\n",
        "print(\"Generating training set...\")\n",
        "training_size = 8350\n",
        "X = np.random.randint(0, 2, size=(training_size, n) ) \n",
        "y = np.zeros((training_size, 1))\n",
        "for i in range(training_size):\n",
        "    y[i] = puf_query(X[i:i+1, :], w)\n",
        "\n",
        "print(\"Training set generated\")\n",
        "\n",
        "# ADD YOUR TRAINING CODE HERE\n",
        "w0 = np.random.randn(n+1, 1) # The estimated value of w.\n",
        "t0 = time.process_time()\n",
        "learning_rate = 0.1\n",
        "for i in range(training_size):\n",
        "    c = X[i:i+1,:]\n",
        "    phi = np.ones(n+1)\n",
        "    phi[n] = 1\n",
        "    for j in range(n-1, -1, -1):\n",
        "        phi[j] = (2*c[0,j]-1)*phi[j+1]\n",
        "    z = np.dot(phi, w0)\n",
        "    y_pred = 1/(1+np.exp(-z))\n",
        "    error = y[i][0] - y_pred\n",
        "    delta = learning_rate * error * y_pred * (1-y_pred) * phi.reshape((n+1,1))\n",
        "    w0 = w0 + delta\n",
        "\n",
        "t1 = time.process_time()\n",
        "training_time = t1 - t0  # time taken to get w0\n",
        "print(\"Training time:\", training_time)\n",
        "print(\"Training size:\", training_size)\n",
        "\n",
        "# Evaluate your result\n",
        "n_test = 10000\n",
        "correct = 0\n",
        "for i in range(1, n_test+1):\n",
        "    c_test = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "    #convert 0 to -1\n",
        "    r = puf_query(c_test, w)\n",
        "    r0 = puf_query(c_test, w0)\n",
        "    correct += (r==r0)\n",
        "\n",
        "success_rate = correct/n_test\n",
        "print(\"Success rate:\", success_rate)\n",
        "\n",
        "# If the success rate is less than 99%, a penalty time will be added\n",
        "# One second is add for each 0.01% below 99%.\n",
        "effective_training_time = training_time\n",
        "if success_rate < 0.99:\n",
        "    effective_training_time = training_time + 10000*(0.99-success_rate)\n",
        "print(\"Effective training time:\", effective_training_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission 2: Logistic Regression with LBFGS (Best one yet)"
      ],
      "metadata": {
        "id": "_JvFqXDQ18QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_X(X):\n",
        "    '''\n",
        "      used to transform x to phi\n",
        "    '''\n",
        "    n = X.shape[1]\n",
        "    phi_X = np.ones((X.shape[0], n+1))\n",
        "    phi_X[:, n] = 1\n",
        "    for i in range(n-1, -1, -1):\n",
        "        phi_X[:, i] = (2*X[:, i]-1)*phi_X[:, i+1]\n",
        "    return phi_X\n",
        "\n",
        "\n",
        "def puf_query(c, w):\n",
        "    n = c.shape[1]\n",
        "    phi = np.ones(n+1)\n",
        "    phi[n] = 1\n",
        "    for i in range(n-1, -1, -1):\n",
        "        phi[i] = (2*c[0,i]-1)*phi[i+1]\n",
        "\n",
        "    r = (np.dot(phi, w) > 0)\n",
        "    return r\n",
        "    \n",
        "\n",
        "# Problem Setup\n",
        "target = 0.99  # The desired prediction rate\n",
        "n = 64  # number of stages in the PUF\n",
        "\n",
        "# Initialize the PUF\n",
        "np.random.seed(int(time.time()))\n",
        "data = np.loadtxt(filename)\n",
        "w = np.zeros((n+1, 1))\n",
        "for i in range(1, n+2):\n",
        "    randi_offset = np.random.randint(1, 45481)\n",
        "    w[i-1] = data[randi_offset-1]\n",
        "\n",
        "# Syntax to query the PUF:\n",
        "c = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "r = puf_query(c, w)\n",
        "# you may remove these two lines\n",
        "\n",
        "# You can use the puf_query function to generate your training dataset\n",
        "# ADD YOUR TRAINING CODE HERE\n",
        "\n",
        "# Generate the training dataset\n",
        "print(\"Generating training set...\")\n",
        "training_size = 5500\n",
        "np.random.seed(42)\n",
        "X = np.random.randint(0, 2, size=(training_size, n)) \n",
        "y = np.zeros((training_size, 1))\n",
        "for i in range(training_size):\n",
        "    y[i] = puf_query(X[i:i+1, :], w)\n",
        "\n",
        "print(\"Training set generated\")\n",
        "\n",
        "# Train the decision tree\n",
        "t0 = time.process_time()\n",
        "dt = LogisticRegression()\n",
        "X = transform_X(X)\n",
        "dt.fit(X, y.ravel())\n",
        "t1 = time.process_time()\n",
        "training_time = t1 - t0\n",
        "print(\"Training time:\", training_time)\n",
        "\n",
        "# Evaluate the decision tree\n",
        "n_test = 10000\n",
        "correct = 0\n",
        "for i in range(1, n_test+1):\n",
        "    c_test = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "    r = puf_query(c_test, w)\n",
        "    c_test = transform_X(c_test)\n",
        "    r_dt = dt.predict(c_test)\n",
        "    correct += (r==r_dt)\n",
        "\n",
        "success_rate = correct/n_test\n",
        "print(\"Success rate:\", success_rate)\n",
        "\n",
        "# If the success rate is less than 99%, a penalty time will be added\n",
        "# One second is add for each 0.01% below 99%.\n",
        "effective_training_time = training_time\n",
        "if success_rate < 0.99:\n",
        "    effective_training_time = training_time + 10000*(0.99-success_rate)\n",
        "print(\"Effective training time:\", effective_training_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVJmBxXu2BMK",
        "outputId": "74c17d15-e948-4192-bb0c-48776168e2fd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training set...\n",
            "Training set generated\n",
            "Training time: 0.062490379999985635\n",
            "Success rate: [0.9923]\n",
            "Effective training time: 0.062490379999985635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission 3: SVM with SMO"
      ],
      "metadata": {
        "id": "6t984YKX4P5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def puf_query(c, w):\n",
        "    n = c.shape[1]\n",
        "    phi = np.ones(n+1)\n",
        "    phi[n] = 1\n",
        "    for i in range(n-1, -1, -1):\n",
        "        phi[i] = (2*c[0,i]-1)*phi[i+1]\n",
        "\n",
        "    r = (np.dot(phi, w) > 0)\n",
        "    return r\n",
        "\n",
        "def transform_X(X):\n",
        "    n = X.shape[1]\n",
        "    phi_X = np.ones((X.shape[0], n+1))\n",
        "    phi_X[:, n] = 1\n",
        "    for i in range(n-1, -1, -1):\n",
        "        phi_X[:, i] = (2*X[:, i]-1)*phi_X[:, i+1]\n",
        "    return phi_X\n",
        "\n",
        "# Problem Setup\n",
        "target = 0.99  # The desired prediction rate\n",
        "n = 64  # number of stages in the PUF\n",
        "\n",
        "# Initialize the PUF\n",
        "np.random.seed(int(time.time()))\n",
        "data = np.loadtxt('weight_diff.txt')\n",
        "w = np.zeros((n+1, 1))\n",
        "for i in range(1, n+2):\n",
        "    randi_offset = np.random.randint(1, 45481)\n",
        "    w[i-1] = data[randi_offset-1]\n",
        "\n",
        "# Syntax to query the PUF:\n",
        "c = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "r = puf_query(c, w)\n",
        "# you may remove these two lines\n",
        "\n",
        "# You can use the puf_query function to generate your training dataset\n",
        "# ADD YOUR DATASET GENERATION CODE HERE\n",
        "print(\"Generating training set...\")\n",
        "training_size = 6500\n",
        "X = np.random.randint(0, 2, size=(training_size, n)) \n",
        "y = np.zeros((training_size, 1))\n",
        "for i in range(training_size):\n",
        "    y[i] = puf_query(X[i:i+1, :], w)\n",
        "\n",
        "print(\"Training set generated\")\n",
        "\n",
        "# Train SVM using Newton's method\n",
        "print(\"Training SVM...\")\n",
        "clf = SVC(kernel='linear', C=1.0)\n",
        "t0 = time.process_time()\n",
        "clf.fit(transform_X(X), y.ravel())\n",
        "t1 = time.process_time()\n",
        "training_time = t1 - t0  # time taken to train SVM\n",
        "print(\"Training time:\", training_time)\n",
        "print(\"Training size:\", training_size)\n",
        "\n",
        "# Evaluate your result\n",
        "n_test = 10000\n",
        "correct = 0\n",
        "for i in range(1, n_test+1):\n",
        "    c_test = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "    r = puf_query(c_test, w)\n",
        "    r0 = clf.predict(transform_X(c_test))\n",
        "    correct += (r==r0)\n",
        "\n",
        "success_rate = correct/n_test\n",
        "print(\"Success rate:\", success_rate)\n",
        "\n",
        "# If the success rate is less than 99%, a penalty time will be added\n",
        "# One second is add for each 0.01% below 99%.\n",
        "effective_training_time = training_time\n",
        "if success_rate < 0.99:\n",
        "    effective_training_time = training_time + 10000*(0.99-success_rate)\n",
        "print(\"Effective training time:\", effective_training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy-gnI9F4NH3",
        "outputId": "61e71724-d38c-469b-cc0a-30b1c7608a03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training set...\n",
            "Training set generated\n",
            "Training SVM...\n",
            "Training time: 0.7570978469999972\n",
            "Training size: 6500\n",
            "Success rate: [0.991]\n",
            "Effective training time: 0.7570978469999972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission 4: AdaBoost"
      ],
      "metadata": {
        "id": "cP_ErtWt5cRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def puf_query(c, w):\n",
        "    n = c.shape[1]\n",
        "    phi = np.ones(n+1)\n",
        "    phi[n] = 1\n",
        "    for i in range(n-1, -1, -1):\n",
        "        phi[i] = (2*c[0,i]-1)*phi[i+1]\n",
        "\n",
        "    r = (np.dot(phi, w) > 0)\n",
        "    return r\n",
        "\n",
        "# Problem Setup\n",
        "target = 0.99  # The desired prediction rate\n",
        "n = 64  # number of stages in the PUF\n",
        "\n",
        "# Initialize the PUF\n",
        "np.random.seed(int(time.time()))\n",
        "data = np.loadtxt('weight_diff.txt')\n",
        "w = np.zeros((n+1, 1))\n",
        "for i in range(1, n+2):\n",
        "    randi_offset = np.random.randint(1, len(data)+1)\n",
        "    w[i-1] = data[randi_offset-1]\n",
        "\n",
        "# Syntax to query the PUF:\n",
        "c = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "r = puf_query(c, w)\n",
        "# you may remove these two lines\n",
        "\n",
        "# You can use the puf_query function to generate your training dataset\n",
        "# ADD YOUR DATASET GENERATION CODE HERE\n",
        "training_size = 10000\n",
        "training_c = []\n",
        "training_r = []\n",
        "\n",
        "for i in range(0,training_size):\n",
        "  c = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "  r = puf_query(c, w)\n",
        "\n",
        "  n = c.shape[1]\n",
        "  phi = np.ones(n+1)\n",
        "  phi[n] = 1\n",
        "  for j in range(n-1, -1, -1):\n",
        "        phi[j] = (2*c[0,j]-1)*phi[j+1]\n",
        "  training_c.append(phi)\n",
        "  training_r.append(r)\n",
        "\n",
        "\n",
        "training_c = np.array(training_c).reshape(training_size,-1)\n",
        "training_r = np.array(training_r).reshape(training_size,-1)\n",
        "\n",
        "\n",
        "w0 = np.zeros((n+1, 1))  # The estimated value of w.\n",
        "# Try to estimate the value of w here. This section will be timed. You are\n",
        "# allowed to use the puf_query function here too, but it will count towards\n",
        "# the training time.\n",
        "t0 = time.process_time()\n",
        "# ADD YOUR TRAINING CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "model = AdaBoostClassifier()\n",
        "model.fit(training_c, training_r)\n",
        "\n",
        "# for i in range(1, n+2):\n",
        "#     randi_offset = np.random.randint(1, len(data)+1)\n",
        "#     w0[i-1] = data[randi_offset-1]\n",
        "\n",
        "\n",
        "\n",
        "t1 = time.process_time()\n",
        "training_time = t1 - t0  # time taken to get w0\n",
        "print(\"Training time:\", training_time)\n",
        "print(\"Training size:\", training_size)\n",
        "\n",
        "# Evaluate your result\n",
        "n_test = 10000\n",
        "correct = 0\n",
        "for i in range(1, n_test+1):\n",
        "    c_test = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "    r = puf_query(c_test, w)\n",
        "    # r0 = puf_query(c_test, w0)\n",
        "\n",
        "    n = c_test.shape[1]\n",
        "    phi_test = np.ones(n+1)\n",
        "    phi_test[n] = 1\n",
        "    for j in range(n-1, -1, -1):\n",
        "          phi_test[j] = (2*c_test[0,j]-1)*phi_test[j+1]\n",
        "    r0 =  model.predict(phi_test.reshape(1, -1))\n",
        "    correct += (r==r0)\n",
        "\n",
        "success_rate = correct/n_test\n",
        "print(\"Success rate:\", success_rate)\n",
        "\n",
        "# If the success rate is less than 99%, a penalty time will be added\n",
        "# One second is add for each 0.01% below 99%.\n",
        "effective_training_time = training_time\n",
        "if success_rate < 0.99:\n",
        "    effective_training_time = training_time + 10000*(0.99-success_rate)\n",
        "print(\"Effective training time:\", effective_training_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYF4eqbU5fGM",
        "outputId": "fcc6bbe6-1f00-40cb-dbf3-0f0747494951"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.8493677120000029\n",
            "Training size: 10000\n",
            "Success rate: [0.9223]\n",
            "Effective training time: [677.84936771]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission 5: GradientBoost"
      ],
      "metadata": {
        "id": "B1_FXE1N6RTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.process_time()\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(training_c, training_r)\n",
        "\n",
        "t1 = time.process_time()\n",
        "training_time = t1 - t0  # time taken to get w0\n",
        "print(\"Training time:\", training_time)\n",
        "print(\"Training size:\", training_size)\n",
        "\n",
        "# Evaluate your result\n",
        "n_test = 10000\n",
        "correct = 0\n",
        "for i in range(1, n_test+1):\n",
        "    c_test = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
        "    r = puf_query(c_test, w)\n",
        "    # r0 = puf_query(c_test, w0)\n",
        "\n",
        "    n = c_test.shape[1]\n",
        "    phi_test = np.ones(n+1)\n",
        "    phi_test[n] = 1\n",
        "    for j in range(n-1, -1, -1):\n",
        "          phi_test[j] = (2*c_test[0,j]-1)*phi_test[j+1]\n",
        "    r0 =  model.predict(phi_test.reshape(1, -1))\n",
        "    correct += (r==r0)\n",
        "\n",
        "success_rate = correct/n_test\n",
        "print(\"Success rate:\", success_rate)\n",
        "\n",
        "# If the success rate is less than 99%, a penalty time will be added\n",
        "# One second is add for each 0.01% below 99%.\n",
        "effective_training_time = training_time\n",
        "if success_rate < 0.99:\n",
        "    effective_training_time = training_time + 10000*(0.99-success_rate)\n",
        "print(\"Effective training time:\", effective_training_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J65JCkaz6QxV",
        "outputId": "d93d69a6-68d0-4948-eb25-3ed08777e354"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 2.980349426999993\n",
            "Training size: 10000\n",
            "Success rate: [0.8783]\n",
            "Effective training time: [1119.98034943]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission 6: Gradient Descent (Please check the matlab code)"
      ],
      "metadata": {
        "id": "FaRYU5wm7rAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission 7: Stochastic Gradient Descent with Absolute Error"
      ],
      "metadata": {
        "id": "si6XBFUY8KB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PUF():\n",
        "\n",
        "  def __init__(self, n):\n",
        "    np.random.seed(int(time.time()))\n",
        "    data = np.loadtxt('weight_diff.txt')\n",
        "    \n",
        "    self.N = n\n",
        "    self.TARGET = 0.99\n",
        "    self.w = np.zeros((n+1, 1))\n",
        "    self.size = -1\n",
        "    self.train_time = -1\n",
        "    self.eval_time = -1\n",
        "\n",
        "    for i in range(1, n+2):\n",
        "      randi_offset = np.random.randint(1, 45481)\n",
        "      self.w[i-1] = data[randi_offset-1]\n",
        "\n",
        "  def phi(self, c):\n",
        "    n = c.shape[-1]\n",
        "    p = np.ones(n+1)\n",
        "    p[n] = 1\n",
        "    for i in range(n-1, -1, -1):\n",
        "      p[i] = (2 * c[0,i] - 1) * p[i+1]\n",
        "\n",
        "    return p\n",
        "\n",
        "  def query(self, c, w=None, debug=False):\n",
        "    phi = self.phi(c)\n",
        "    if w is not None:\n",
        "      r = (np.dot(phi, w) > 0)\n",
        "    else:\n",
        "      r = (np.dot(phi, self.w) > 0)\n",
        "\n",
        "    if debug:\n",
        "      print(\"Phi: \", phi, \"W: \", self.w, sep=\"\\n\")\n",
        "\n",
        "    return r\n",
        "\n",
        "  def make_samples(self, size):\n",
        "    assert size > 0\n",
        "    self.size = size\n",
        "    c = np.random.randint(0, 2, size=(size, 1, self.w.shape[0] - 1))\n",
        "    phi = np.array([self.phi(i) for i in c])\n",
        "    r = np.array([self.query(i) for i in c])\n",
        "\n",
        "    return c, phi, r\n",
        "\n",
        "  def train(self, train_fn):\n",
        "    t0 = time.process_time()\n",
        "\n",
        "    model = train_fn()\n",
        "\n",
        "    t1 = time.process_time()\n",
        "    self.train_time = t1 - t0                             \n",
        "    print(\"Training time:\", self.train_time)\n",
        "    print(\"Training size:\", self.size)\n",
        "\n",
        "    return model\n",
        "\n",
        "  def eval(self, pred=None, weights=None, eval_weights=False):\n",
        "    n_test = 10000\n",
        "    correct = 0\n",
        "    for i in range(1, n_test + 1):\n",
        "      c_test = np.random.randint(0, 2, size=(1, self.N))\n",
        "      r_test = self.query(c_test)\n",
        "\n",
        "      if eval_weights:\n",
        "        assert len(weights)\n",
        "        r_pred = self.query(c_test, weights)\n",
        "      else:\n",
        "        assert pred\n",
        "        c_test = self.phi(c_test).reshape(1, -1)\n",
        "        r_pred = pred(c_test)\n",
        "      \n",
        "      correct += (r_test == r_pred)\n",
        "\n",
        "    success_rate = correct/n_test\n",
        "    print(\"Success rate:\", success_rate)\n",
        "\n",
        "    # If the success rate is less than 99%, a penalty time will be added\n",
        "    # One second is add for each 0.01% below 99%.\n",
        "    effective_training_time = self.train_time\n",
        "    if success_rate < 0.99:\n",
        "        effective_training_time = self.train_time + 10000*(0.99-success_rate)\n",
        "    print(\"Effective training time:\", effective_training_time)\n",
        "\n",
        "  def info(self):\n",
        "    return {'n': self.N, 'target': self.TARGET}"
      ],
      "metadata": {
        "id": "9a2UcHnY7qZh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "puf = PUF(64)\n",
        "\n",
        "X, X_phi, y = puf.make_samples(10000)\n",
        "     "
      ],
      "metadata": {
        "id": "H4qbPryhh6Du"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd_train():\n",
        "  n = 64\n",
        "  w0 = np.zeros((n+1, 1))  # The estimated value of w.\n",
        "  for i in range(n+1):\n",
        "      w0[i] = np.random.rand()*0.1 - 0.05\n",
        "\n",
        "  eta = 0.0001  # learning rate\n",
        "  for t in range(10):\n",
        "      for i in range(len(y)):\n",
        "          c = X[i].flatten()\n",
        "          r = y[i]\n",
        "          phi = X_phi[i]\n",
        "\n",
        "          h = (np.dot(phi, w0) > 0)\n",
        "          e = float(r) - h\n",
        "          delta_w = eta * e * phi.reshape(n+1,1)\n",
        "          w0 = w0 + delta_w\n",
        "\n",
        "  return w0\n",
        "\n",
        "sgd_weights = puf.train(sgd_train)\n",
        "\n",
        "puf.eval(weights=sgd_weights, eval_weights=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxjuJ2K3h8gf",
        "outputId": "2794e584-599f-4f80-a984-f11063fb4934"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 1.6915694369999983\n",
            "Training size: 10000\n",
            "Success rate: [0.9937]\n",
            "Effective training time: 1.6915694369999983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Submission 8: XGBoost"
      ],
      "metadata": {
        "id": "hao7-yMTiZKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_train():\n",
        "  xgb = xg.XGBClassifier()\n",
        "  xgb.fit(X_phi, y.ravel())\n",
        "  return xgb\n",
        "\n",
        "xgb = puf.train(xgb_train)\n",
        "\n",
        "puf.eval(pred=xgb.predict)"
      ],
      "metadata": {
        "id": "e_gOcDxtiR3r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}