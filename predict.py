# -*- coding: utf-8 -*-
"""predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dHBuLhlKnVLwPYkCkqW7zP4QKWev7tkU
"""

import os

from google.colab import files
from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)
os.chdir('gdrive/My Drive/MSML 604 Project')

import torch
import numpy as np
import time
from sklearn.model_selection import train_test_split

def puf_query(c, w):
    n = c.shape[1]
    phi = np.ones(n+1)
    phi[n] = 1
    for i in range(n-1, -1, -1):
        phi[i] = (2*c[0,i]-1)*phi[i+1]

    r = (np.dot(phi, w) > 0)
    return r

# Problem Setup
target = 0.99  # The desired prediction rate
n = 64  # number of stages in the PUF

# Initialize the PUF
np.random.seed(int(time.time()))
data = np.loadtxt('weight_diff.txt')
w = np.zeros((n+1, 1))
for i in range(1, n+2):
    randi_offset = np.random.randint(1, len(data)+1)
    w[i-1] = data[randi_offset-1]

# Syntax to query the PUF:
c = np.random.randint(0, 2, size=(1, n))  # a random challenge vector
r = puf_query(c, w)
# you may remove these two lines

# You can use the puf_query function to generate your training dataset
# ADD YOUR DATASET GENERATION CODE HERE
training_size = 100
training_c = []
training_r = []

for i in range(0,training_size):
  c = np.random.randint(0, 2, size=(1, n))  # a random challenge vector
  r = puf_query(c, w)
  # temp = np.concatenate((c, r), axis=None)
  
  training_c.append(c)
  training_r.append(r)

training_c = np.array(training_c).reshape(100,-1)
training_r = np.array(training_r).reshape(100,-1)

X_train, X_test, y_train, y_test = train_test_split(training_c, training_r, test_size=0.20, random_state=42)

w0 = np.zeros((n+1, 1))  # The estimated value of w.
# Try to estimate the value of w here. This section will be timed. You are
# allowed to use the puf_query function here too, but it will count towards
# the training time.
t0 = time.process_time()
# ADD YOUR TRAINING CODE HERE
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X_train, y_train)

# for i in range(1, n+2):
#     randi_offset = np.random.randint(1, len(data)+1)
#     w0[i-1] = data[randi_offset-1]



t1 = time.process_time()
training_time = t1 - t0  # time taken to get w0
print("Training time:", training_time)
print("Training size:", training_size)

pred = model.predict(X_test)
pred

# Evaluate your result
n_test = 10000
correct = 0
for i in range(1, n_test+1):
    c_test = np.random.randint(0, 2, size=(1, n))  # a random challenge vector
    r = puf_query(c_test, w)
    # r0 = puf_query(c_test, w0)
    r0 =  model.predict(c_test)
    correct += (r==r0)

success_rate = correct/n_test
print("Success rate:", success_rate)

# If the success rate is less than 99%, a penalty time will be added
# One second is add for each 0.01% below 99%.
effective_training_time = training_time
if success_rate < 0.99:
    effective_training_time = training_time + 10000*(0.99-success_rate)
print("Effective training time:", effective_training_time)