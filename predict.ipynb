{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import xgboost as xg\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "kSkSxHFve5bk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_train(X, y):\n",
        "  lr = LogisticRegression()\n",
        "  lr.fit(X, y)\n",
        "  return lr\n",
        "\n",
        "def svc_train(X, y):\n",
        "  svc = SVC()\n",
        "  svc.fit(X, y)\n",
        "  return svc\n",
        "\n",
        "def xgb_train(X, y):\n",
        "  xgb = xg.XGBClassifier()\n",
        "  xgb.fit(X, y)\n",
        "  return xgb\n",
        "\n",
        "# SGD Training\n",
        "# w0 = np.zeros((n+1, 1))  # The estimated value of w.\n",
        "# t0 = time.process_time()\n",
        "# for i in range(n+1):\n",
        "#     w0[i] = np.random.rand()*0.1 - 0.05\n",
        "\n",
        "# eta = 0.01  # learning rate\n",
        "# for t in range(100):\n",
        "#     for i in range(training_size):\n",
        "#         c = X[i:i+1,:]\n",
        "#         r = y[i]\n",
        "#         phi = np.ones(n+1)\n",
        "#         phi[n] = 1\n",
        "#         for j in range(n-1, -1, -1):\n",
        "#             phi[j] = (2*c[0,j]-1)*phi[j+1]\n",
        "\n",
        "#         h = (np.dot(phi, w0) > 0)\n",
        "#         e = r - h\n",
        "#         delta_w = eta * e * phi.reshape(n+1,1)\n",
        "#         w0 = w0 + delta_w"
      ],
      "metadata": {
        "id": "EsK8eLTMQaAI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_phi(c):\n",
        "  n = c.shape[-1]\n",
        "  phi = np.ones(n+1)\n",
        "  phi[n] = 1\n",
        "  for i in range(n-1, -1, -1):\n",
        "    phi[i] = (2*c[0,i]-1)*phi[i+1]\n",
        "\n",
        "  return phi\n",
        "\n",
        "def puf_init(n=64):\n",
        "  np.random.seed(int(time.time()))\n",
        "  data = np.loadtxt('weight_diff.txt')\n",
        "  w = np.zeros((n+1, 1))\n",
        "  for i in range(1, n+2):\n",
        "    randi_offset = np.random.randint(1, 45481)\n",
        "    w[i-1] = data[randi_offset-1]\n",
        "\n",
        "  return w\n",
        "\n",
        "def puf_query(c, w, debug=False):\n",
        "  phi = compute_phi(c)\n",
        "  r = (np.dot(phi, w) > 0)\n",
        "  if debug:\n",
        "    print(\"Phi: \", phi, \"W: \", w, sep=\"\\n\")\n",
        "\n",
        "  return r\n",
        "\n",
        "def make_samples(n, w):\n",
        "  c = np.random.randint(0, 2, size=(n, 1, w.shape[0]-1))\n",
        "  r = np.array([puf_query(i, w) for i in c])\n",
        "\n",
        "  return c, r\n",
        "\n",
        "def train(train_fn, X, y):\n",
        "  t0 = time.process_time()\n",
        "  # ADD YOUR TRAINING CODE HERE\n",
        "\n",
        "  model = train_fn(X, y)\n",
        "\n",
        "  t1 = time.process_time()\n",
        "  training_time = t1 - t0                             # time taken to get w0\n",
        "  print(\"Training time:\", training_time)\n",
        "  print(\"Training size:\", training_size)\n",
        "\n",
        "  return model, training_time\n",
        "\n",
        "def eval(model, training_time, n=64):\n",
        "  n_test = 10000\n",
        "  correct = 0\n",
        "  for i in range(1, n_test+1):\n",
        "    c_test = np.random.randint(0, 2, size=(1, n))     # a random challenge vector\n",
        "    r = puf_query(c_test, w)\n",
        "    c_test = compute_phi(c_test).reshape(1, -1)\n",
        "    r0 = model.predict(c_test)\n",
        "    correct += (r==r0)\n",
        "\n",
        "  success_rate = correct/n_test\n",
        "  print(\"Success rate:\", success_rate)\n",
        "\n",
        "  # If the success rate is less than 99%, a penalty time will be added\n",
        "  # One second is add for each 0.01% below 99%.\n",
        "  effective_training_time = training_time\n",
        "  if success_rate < 0.99:\n",
        "      effective_training_time = training_time + 10000*(0.99-success_rate)\n",
        "  print(\"Effective training time:\", effective_training_time)\n",
        "\n",
        "# Problem Setup\n",
        "target = 0.99                                        # The desired prediction rate\n",
        "n = 64                                               # number of stages in the PUF\n",
        "\n",
        "# Initialize the PUF\n",
        "w = puf_init(n)\n",
        "\n",
        "# You can use the puf_query function to generate your training dataset\n",
        "# ADD YOUR DATASET GENERATION CODE HERE\n",
        "training_size = 10000\n",
        "\n",
        "X, y = make_samples(training_size, w)\n",
        "X = np.array([compute_phi(i) for i in X])\n",
        "\n",
        "for i in [\n",
        "    {\"model\": svc_train, \"name\": \"SVC\"}, \n",
        "    {\"model\": lr_train, \"name\": \"Log Reg\"}, \n",
        "    {\"model\": xgb_train, \"name\": \"XG Boosting\"}]:\n",
        "  print(\"\\n\", \"-\"*20, i[\"name\"], \"-\"*20, sep=\" \", end=\"\\n\")\n",
        "  model, train_time = train(i[\"model\"], X, y.ravel())\n",
        "  eval(model, train_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUNMdmVKJKb2",
        "outputId": "e902d06d-a249-4422-8a44-9ccd7a9c4d28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " -------------------- SVC --------------------\n",
            "Training time: 4.091682948000001\n",
            "Training size: 10000\n",
            "Success rate: [0.9664]\n",
            "Effective training time: [240.09168295]\n",
            "\n",
            " -------------------- Log Reg --------------------\n",
            "Training time: 0.09776696400000162\n",
            "Training size: 10000\n",
            "Success rate: [0.9947]\n",
            "Effective training time: 0.09776696400000162\n",
            "\n",
            " -------------------- XG Boosting --------------------\n",
            "Training time: 4.3665228379999945\n",
            "Training size: 10000\n",
            "Success rate: [0.907]\n",
            "Effective training time: [834.36652284]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X.astype(np.float32))\n",
        "        self.y = torch.from_numpy(y.astype(np.float32))\n",
        "        self.len = self.X.shape[0]\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "   \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(65, 65)\n",
        "        self.a1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(65, 65)\n",
        "        self.a2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(65, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.a1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.a2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model = Net()\n",
        "print(model)\n",
        "     \n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Instantiate training and test data\n",
        "train_data = Data(X, y)\n",
        "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfzbnvg1VK4R",
        "outputId": "7fb86fb8-fa67-4841-e088-76dc57768277"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=65, out_features=65, bias=True)\n",
            "  (a1): ReLU()\n",
            "  (fc2): Linear(in_features=65, out_features=65, bias=True)\n",
            "  (a2): ReLU()\n",
            "  (fc3): Linear(in_features=65, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "loss_values = []\n",
        "\n",
        "t0 = time.process_time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for X, y in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss_values.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(\"Train Loss {:.4f}\".format(loss.item()))\n",
        "\n",
        "t1 = time.process_time()\n",
        "\n",
        "print(\"Training Complete\\nTime: {}\\nAvg. Loss: {}\".format(t1-t0, sum(loss_values)/len(loss_values)))\n",
        "\n",
        "n_test = 10000\n",
        "correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(1, n_test+1):\n",
        "      c_test = np.random.randint(0, 2, size=(1, n))\n",
        "      r = puf_query(c_test, w)\n",
        "      c_test = torch.from_numpy(compute_phi(c_test).astype(np.float32))\n",
        "      r0 = int(model(c_test) > 0)\n",
        "      correct += (r==r0)\n",
        "\n",
        "success_rate = correct/n_test\n",
        "print(\"Success rate:\", success_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4ccq4ItYpTo",
        "outputId": "67b5b83b-f33a-44e3-a68d-9c2d47c413c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Complete\n",
            "Time: 20.959859390999995\n",
            "Avg. Loss: 0.6914078287561988\n",
            "Success rate: [0.5284]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcGugCZ6Ya8e"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}