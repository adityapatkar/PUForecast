{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import xgboost as xg\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "kSkSxHFve5bk"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PUF():\n",
        "\n",
        "  def __init__(self, n):\n",
        "    np.random.seed(int(time.time()))\n",
        "    data = np.loadtxt('weight_diff.txt')\n",
        "    \n",
        "    self.N = n\n",
        "    self.TARGET = 0.99\n",
        "    self.w = np.zeros((n+1, 1))\n",
        "    self.size = -1\n",
        "    self.train_time = -1\n",
        "    self.eval_time = -1\n",
        "\n",
        "    for i in range(1, n+2):\n",
        "      randi_offset = np.random.randint(1, 45481)\n",
        "      self.w[i-1] = data[randi_offset-1]\n",
        "\n",
        "  def phi(self, c):\n",
        "    n = c.shape[-1]\n",
        "    p = np.ones(n+1)\n",
        "    p[n] = 1\n",
        "    for i in range(n-1, -1, -1):\n",
        "      p[i] = (2 * c[0,i] - 1) * p[i+1]\n",
        "\n",
        "    return p\n",
        "\n",
        "  def query(self, c, w=None, debug=False):\n",
        "    phi = self.phi(c)\n",
        "    if w is not None:\n",
        "      r = (np.dot(phi, w) > 0)\n",
        "    else:\n",
        "      r = (np.dot(phi, self.w) > 0)\n",
        "\n",
        "    if debug:\n",
        "      print(\"Phi: \", phi, \"W: \", self.w, sep=\"\\n\")\n",
        "\n",
        "    return r\n",
        "\n",
        "  def make_samples(self, size):\n",
        "    assert size > 0\n",
        "    self.size = size\n",
        "    c = np.random.randint(0, 2, size=(size, 1, self.w.shape[0] - 1))\n",
        "    phi = np.array([self.phi(i) for i in c])\n",
        "    r = np.array([self.query(i) for i in c])\n",
        "\n",
        "    return c, phi, r\n",
        "\n",
        "  def train(self, train_fn):\n",
        "    t0 = time.process_time()\n",
        "\n",
        "    model = train_fn()\n",
        "\n",
        "    t1 = time.process_time()\n",
        "    self.train_time = t1 - t0                             \n",
        "    print(\"Training time:\", self.train_time)\n",
        "    print(\"Training size:\", self.size)\n",
        "\n",
        "    return model\n",
        "\n",
        "  def eval(self, pred=None, weights=None, eval_weights=False):\n",
        "    n_test = 10000\n",
        "    correct = 0\n",
        "    for i in range(1, n_test + 1):\n",
        "      c_test = np.random.randint(0, 2, size=(1, self.N))\n",
        "      r_test = self.query(c_test)\n",
        "\n",
        "      if eval_weights:\n",
        "        assert len(weights)\n",
        "        r_pred = self.query(c_test, weights)\n",
        "      else:\n",
        "        assert pred\n",
        "        c_test = self.phi(c_test).reshape(1, -1)\n",
        "        r_pred = pred(c_test)\n",
        "      \n",
        "      correct += (r_test == r_pred)\n",
        "\n",
        "    success_rate = correct/n_test\n",
        "    print(\"Success rate:\", success_rate)\n",
        "\n",
        "    # If the success rate is less than 99%, a penalty time will be added\n",
        "    # One second is add for each 0.01% below 99%.\n",
        "    effective_training_time = self.train_time\n",
        "    if success_rate < 0.99:\n",
        "        effective_training_time = self.train_time + 10000*(0.99-success_rate)\n",
        "    print(\"Effective training time:\", effective_training_time)\n",
        "\n",
        "  def info(self):\n",
        "    return {'n': self.N, 'target': self.TARGET}"
      ],
      "metadata": {
        "id": "7Omb6W-a4Jhg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "puf = PUF(64)\n",
        "\n",
        "X, X_phi, y = puf.make_samples(10000)"
      ],
      "metadata": {
        "id": "N523TwSfHP41"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_train():\n",
        "  lr = LogisticRegression()\n",
        "  lr.fit(X_phi, y.ravel())\n",
        "  return lr\n",
        "\n",
        "lr = puf.train(lr_train)\n",
        "\n",
        "puf.eval(pred=lr.predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXWp79lbHlve",
        "outputId": "a1276f06-d96c-40c0-8426-b13f39c18f6e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.07705769300000043\n",
            "Training size: 10000\n",
            "Success rate: [0.9932]\n",
            "Effective training time: 0.07705769300000043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def svc_train():\n",
        "  svc = SVC()\n",
        "  svc.fit(X_phi, y.ravel())\n",
        "  return svc\n",
        "\n",
        "svc = puf.train(svc_train)\n",
        "\n",
        "puf.eval(pred=svc.predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXi8Mg1WK3Pd",
        "outputId": "19c435b7-718d-4ea8-f171-0cd850387785"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.9933555380000598\n",
            "Training size: 4490\n",
            "Success rate: [0.9534]\n",
            "Effective training time: [366.99335554]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_train():\n",
        "  xgb = xg.XGBClassifier()\n",
        "  xgb.fit(X_phi, y.ravel())\n",
        "  return xgb\n",
        "\n",
        "xgb = puf.train(xgb_train)\n",
        "\n",
        "puf.eval(pred=xgb.predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJst_c1OLUxj",
        "outputId": "e774fa39-900c-447d-807d-22485f36a936"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 2.059269560000075\n",
            "Training size: 4490\n",
            "Success rate: [0.895]\n",
            "Effective training time: [952.05926956]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd_train():\n",
        "  n = 64\n",
        "  w0 = np.zeros((n+1, 1))  # The estimated value of w.\n",
        "  for i in range(n+1):\n",
        "      w0[i] = np.random.rand()*0.1 - 0.05\n",
        "\n",
        "  eta = 0.0001  # learning rate\n",
        "  for t in range(10):\n",
        "      for i in range(len(y)):\n",
        "          c = X[i].flatten()\n",
        "          r = y[i]\n",
        "          phi = X_phi[i]\n",
        "\n",
        "          h = (np.dot(phi, w0) > 0)\n",
        "          e = float(r) - h\n",
        "          delta_w = eta * e * phi.reshape(n+1,1)\n",
        "          w0 = w0 + delta_w\n",
        "\n",
        "  return w0\n",
        "\n",
        "sgd_weights = puf.train(sgd_train)\n",
        "\n",
        "puf.eval(weights=sgd_weights, eval_weights=True)"
      ],
      "metadata": {
        "id": "EsK8eLTMQaAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023b8cfe-d272-4658-ff2f-7eed4300fb9c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.5164980439999454\n",
            "Training size: 4490\n",
            "Success rate: [0.9893]\n",
            "Effective training time: [7.51649804]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp_train():\n",
        "  mlp = MLPClassifier(solver='lbfgs', learning_rate_init=0.0001)\n",
        "  mlp.fit(X_phi, y.ravel())\n",
        "  return mlp\n",
        "\n",
        "mlp = puf.train(mlp_train)\n",
        "\n",
        "puf.eval(pred=mlp.predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDl4ANySOzKc",
        "outputId": "161e6af4-e929-4683-e2a5-10ea8324f56a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.5814883430000464\n",
            "Training size: 4490\n",
            "Success rate: [0.9867]\n",
            "Effective training time: [33.58148834]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X.astype(np.float32))\n",
        "        self.y = torch.from_numpy(y.astype(np.float32))\n",
        "        self.len = self.X.shape[0]\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "   \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(65, 65)\n",
        "        self.a1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(65, 65)\n",
        "        self.a2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(65, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.a1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.a2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model = Net()\n",
        "print(model)\n",
        "     \n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Instantiate training and test data\n",
        "train_data = Data(X, y)\n",
        "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "rfzbnvg1VK4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "loss_values = []\n",
        "\n",
        "t0 = time.process_time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for X, y in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss_values.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(\"Train Loss {:.4f}\".format(loss.item()))\n",
        "\n",
        "t1 = time.process_time()\n",
        "\n",
        "print(\"Training Complete\\nTime: {}\\nAvg. Loss: {}\".format(t1-t0, sum(loss_values)/len(loss_values)))\n",
        "\n",
        "n_test = 10000\n",
        "correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(1, n_test+1):\n",
        "      c_test = np.random.randint(0, 2, size=(1, n))\n",
        "      r = puf_query(c_test, w)\n",
        "      c_test = torch.from_numpy(compute_phi(c_test).astype(np.float32))\n",
        "      r0 = int(model(c_test) > 0)\n",
        "      correct += (r==r0)\n",
        "\n",
        "success_rate = correct/n_test\n",
        "print(\"Success rate:\", success_rate)"
      ],
      "metadata": {
        "id": "U4ccq4ItYpTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcGugCZ6Ya8e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}